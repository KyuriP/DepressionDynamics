---
title: "Modelling Dynamics of Depressive Symptoms"
subtitle: "Taking Computational Modeling Approach"
institute: "Apr 2, 2024"  #change for defense May 22, 2023
author: "Kyuri Park"
format: 
  revealjs:
    embed-resources: true
    logo: img/csl_logo.png
    footer: "Computational Science Lab - University of Amsterdam"
    theme: [default, custom.scss]
    slide-number: c/t
    transition: fade
    transition-speed: slow
    background-transition: fade
    preview-links: auto
    html-math-method: mathjax
    auto-stretch: false
    # chalkboard:
    #   boardmarker-width: 5
from: markdown+emoji
title-slide-attributes:
    data-background-image: img/bg_bwcsl.png
    data-background-size: "cover"
    data-background-opacity: "1"
execute:
  echo: false
bibliography: main_ref.bib
csl: "apa.csl"
editor: 
  markdown: 
    wrap: sentence
---

```{r, include=F}
library(knitr)
library(kableExtra)
```

::: notes
Hello, I am Kyuri, I am a PhD student working at the Computational Science Lab at the university of amsterdam.
The main project I am working for is about modelling depression dynamics with regard to precariousness factors mainly in the context of Amsterdam city.
I think the main question we have is what kind of precariousness factors are mainly involved and we want to learn about the dynamical relationships so that ultimately we can understand where to intervene in the system to prevent fully-blown depression and minimize the mental health problems in the city.
That's the grand scheme, but as a first baby step, I've started working on modeling depression symptoms, which is the work that I am planning to present today.
:::

## Network theory of psychopathology

Mental disorder is produced by direct causal interactions between symptoms that reinforce each other via feedback loops.
[@BorsboomCramer2013].

::: r-stack
![](img/cycle1.png){.fragment fig-align="center" width="450"}

![](img/cycle2.png){.fragment fig-align="center" width="450"}

![](img/cycle3.png){.fragment fig-align="center" width="450"}

![](img/cycle4.png){.fragment fig-align="center" width="450"}

![](img/cycle5.png){.fragment fig-align="center" width="450"}

![](img/cycle2.png){.fragment fig-align="center" width="450"}

![](img/cycle3.png){.fragment fig-align="center" width="450"}

![](img/cycle4.png){.fragment fig-align="center" width="450"}

![](img/cycle5.png){.fragment fig-align="center" width="450"}
:::

::: notes
The main foundation for me when I start looking into modelling the depression symptom dynamics is the network theory of psychopathology of Denny, which says mental disorder is produced by direct causal interactions between the symptoms.
And the crucial point here is that, these causal interactions often form feedback loops and they reinforce each other.
As you can see here, feeling down makes you sleep poorly and lack of sleep makes you feel tired and it sort of forms this vicious cycle.
Like that symptom activation spreads throughout the network, and when those cyclic relationships become strong enough and symptom activation sustains itself, that manifests as a depression.
So that's the gist of the theory.
:::

## Fundamental features of depression dynamics

::: {#citeborsboom}
[@borsboom2017network; @cramer_major_2016]
:::

1.  [Bistability]{.fragment .highlight-current-red fragment-index="1"}

2.  [Network connectivity]{.fragment .highlight-current-red fragment-index="2"}

3.  Hysteresis

4.  Resilience

::: r-stack
![](img/landscape.png){.absolute .fragment .fade-in-then-out top="90" left="545" width="403.5" height="317" fragment-index="1"}

![](img/landscape_networks.png){.absolute .fragment .fade-in top="90" left="500" width="540" height="600" fragment-index="2"}
:::

::: notes
Given the network theory, here I picked four fundamental features of depression dynamics to focus on in this study and test with my model.
The first one is bistability, which suggests that depression, as a dynamic system, exhibits two stable states: one represents healthy state and the other represents depressed state.
This notion is often illustrated using an energy landscape analogy with hills and valleys like this.

And second one is network connectivity.
With the introduction of the network theory, there has been increasing evidence that various patient groups have stronger network connections compared to healthy controls.
Accordingly, the two stable states are presumed to be distinguishable by a weakly connected network in the healthy population and a strongly connected network in the depressed population.
:::

## Fundamental features of depression dynamics {.scrollable}

<div>

[@borsboom2017network; @cramer_major_2016]

</div>

<div>

1.  Bistability

2.  Network connectivity

3.  [Hysteresis]{style="color:#FF0000"}

4.  Resilience

</div>

::: r-stack
![](img/hysteresis0.png){.absolute top="380" left="20"} ![](img/hysteresis1.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="1" width="2600"} ![](img/hysteresis2.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="2" width="2600"} ![](img/hysteresis3.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="3" width="2600"} ![](img/hysteresis4.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="4" width="2600"} ![](img/hysteresis5.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="5" width="2600"} ![](img/hysteresis6.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="6" width="2600"} ![](img/hysteresis7.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="7" width="2600"} ![](img/hysteresis8.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="8" width="2600"} ![](img/resilience1.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="9" width="2600"}
:::

::: notes
Third one is hysteresis.
In psychopathology, hysteresis refers to, quoting Denny, the phenomenon that symptoms continue to activate each other, even after the triggering factor has disappeared.

In this figure, the shaded area represents the period when the system experiences stress or shock.
Even after this trigger has been removed, the system does not return to a healthy state immediately but remains lingering near the depressed state.
This persistence in symptom activation, irrespective of the absence of external triggers, illustrates hysteresis within the system.

As you see here with the symptom network representation, the symptom gets activated with the external trigger, but even with the absence of trigger, the symptoms remain activated.
So this property right here is called hysteresis.
(CLICK)

And this network that has relatively strong connection with feedback loops, which enables hysteresis effect to show, we call it a vulnerable network or low resilient network.
Although here I did not indicate the causal directions but I assume these three nodes form a cycle.
:::

## Fundamental features of depression dynamics {.scrollable}

<div>

[@borsboom2017network; @cramer_major_2016]

</div>

<div>

1.  Bistability

2.  Network connectivity

3.  Hysteresis

4.  [Resilience]{style="color:#FF0000"}

</div>

::: r-stack
![](img/resilience1.png){.absolute .fragment .fade-out top="380" left="20" width="2600" fragment-index="1"} <!-- ![](img/resilience2.png){.absolute .fragment .fade-up top="380" left="20" fragment-index="1" width="2600"} --> ![](img/resilience3.png){.absolute .fragment .fade-up top="380" left="20" width="920" fragment-index="1"}
![](img/resilience4.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="2" width="1500"} ![](img/resilience5.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="3" width="1500"}
:::

::: notes
This resilience concept is the last point.
Contrary to this low resilient network, when the network relatively has weak connections, we call it highly resilient network.
Because in this case, the symptom activation does not easily propagate through the network and hysteresis can therefore be hardly observed.

In this study, with our model, we assess whether we can replicate these features of depression dynamics, except for bistability.
We would more or less presume that our system has bistability and we formalize our model such that it satisfies this condition.
For the rest, we will see whether our model can retrieve such features.
For example, for resilience, we will specify different levels of resilience within our model and examine whether the resulting statistical network models exhibit different structures.
So this is sort of top-down approach, evaluating whether the proposed features of depression dynamics are supported within our modeling framework.
:::

## Toy model {.scrollable}

Use the average of three empirical weight matrices with causal directions primarily guided by empirical evidence [@ramos-vera_network_2021; @lee_measurement_2023; @jing_comparing_2023].

::: r-stack
![](img/netA.png){.absolute .fragment .semi-fade-out left="0" top="200" width="450" fragment-index="1"} ![](img/toymodel.png){.absolute .fragment .fade-in right="0" top="200" width="600" fragment-index="1"}
:::

::: notes
So this is the toy model we used.
I didn't really have any data back then, so what I did was basically that I found three empirical studies which estimated statistical networks and I average their weight matrices.
And then, given some empirical evidence but mainly more of common sense, I assigned the causal directions, which results in this A matrix.
When visualized in a network, we get this.
Note that the self-loops are included in our model even though empirical networks did not have those.
And also all these causal links are positive, meaning that every feedback loops are reinforcing.
Lastly, here, i colored the nodes that are part of cycles in orange, and the ones that are not part of any cycles in blue.
I have done this, in case if the nodes that are part of cycles show any differences from the ones that are not later in our simulation.
:::

## Formalizing dynamics {.smaller .scrollable}

-   Deterministic differential equation (`ODE`^1^):

<br> <br>

```{=tex}
\begin{equation} \label{eq:2}
\frac{dS_i}{dt} = S_i(1-S_i)(\beta_i + \alpha_{ii}S_i + \sum_{i \neq j}\alpha_{ji}S_j(1 + \delta_i f(S_i)))
\end{equation}
```
<br> <br>

-   Add (white) noise (`SDE`^2^):

```{=tex}
\begin{equation} \label{eq:3}
dS_{i} = S_{i}(1-S_{i})(\beta_i + \alpha_{ii} S_{i} + \sum_{i \neq j}\alpha_{ji}S_{j}(1+\delta_i f(S_{i}))) dt + \sigma_i dW
\end{equation}
```
<br>

::: {#footnotes_eq}
^1^: Ordinary Differential Equation.\
^2^: Stochastic Differential Equation.\
$f(x) = x^2$.
:::

<br> <br> <br> <br> <br> <br> <br>

#### Description of parameters

| Parameter  | Description                                                                                                                                                                                             |
|--------------------------|:---------------------------------------------|
| $\beta_i$  | The sensitivity level of $S_i$ to external triggering factors.                                                                                                                                          |
| $\alpha$   | The elements of the weight matrix $\mathbf{A}$. <BR> $\alpha_{ij}$ refers to the weight of the edge $S_i \rightarrow S_j$ and $\alpha_{ii}$ refers to the weight of the self-reinforcing loop of $S_i$. |
| $\delta_i$ | The boosting factor that amplifies the effect of other $S_j$'s on $S_i$.                                                                                                                                |
| $\sigma_i$ | The scaling factor that controls the strength of the stochastic term.                                                                                                                                   |

![](img/bifurcation_W.png){fig-align="center"}

::: notes
So this is the model we used for symptom dynamics.
The first top expression shows the ODE, the ordinary differential equation, defining the interaction between the symptoms.
So the $S_i$ here corresponds to a symptom i.
The first two terms $S_i(1-S_i)$ are typical logistic differential equations, which we put to constrain the symptom level between 0 and 1.
We imposed this constraint to align with the common practice of measuring symptoms on bounded scales in questionnaires.
In this context, approaching 0 means a low symptom level, indicating symptom deactivation, and approaching 1 indicates symptom activation.

The third term is a sum of three elements that collectively determine the symptom level.
Here, $\beta_i$ represents the sensitivity level of $S_i$.
A lower $\beta_i$ indicates reduced sensitivity to external triggering factors, making the symptom less prone to activation.
It is an important parameter, which heavily influences the system's tipping point, so I will talk about this in more detail in the following slide

$\alpha$ denotes the weight of edges in the network, basically the elements of matrix $\mathbf{A}$.
$\alpha_{ji}$ represents the impact of $S_j$ on $S_i$, and $\delta_i$ acts as a booster, making the influence of other symptoms on $S_i$ stronger, depending on the current level of $S_i$.
We define $f$ to be a quadratic function, so in the end what it says is that, as the $S_i$ level increases, the effects of other symptoms are amplified by $\delta_i \cdot S_i^2$.
So here we used quadratic function because it seems one of the simplest function I could think of for a monotonic non-linear increasing function, but it was my arbitrary choice; eventually any monotnoic increasing function would've been fine.
So this term actually adds nonlinearity into our mode as this is the interaction term between $S_i$ and $S_j$ and also as we use the quadratic function for f, it enables our model to capture the nonliear responses.

Any questions?...
It would be insane if everything clicks now, just let it sink for now, and it will become hopefully clearer when I show you the plots on how the model behaves.

And this second equation, is just to show that we introduced the noise to our model to capture the inherent randomness observed in symptom dynamics.
The noise is usually seen as blurring trajectories in deterministic systems, but the noise can actually facilitate transitions between different states, so the strength of this noise is therefore very important in modeling the dynamics.
Here we control the noise strength with $\sigma_i$.
And the underlying nature of the noise in our model is Gaussian white noise, which is a common choice for capturing random fluctuations.
Adding this noise term, we can describe the dynamics of symptoms with a SDE, the stochastic differential equation which is shown right here.
So that is all the equation I have.

So, this is a quick summary of what are the different parameters doing in our model.
Are these okay-ish clear?
Then I will show you a bit more in detail how does the dynamics look given this model.
:::

## Specifying parameters

::: r-stack
![](img/bifurcation_beta1.png){.absolute top="200" left="180" width="660"} ![](img/bifurcation_beta2.png){.absolute .fragment .fade-in top="170" left="163" width="678"} ![](img/bifurcation_beta3.png){.absolute .fragment .fade-in top="119" left="162" width="677"} ![](img/bifurcation_beta4.png){.absolute .fragment .fade-in top="109" left="163" width="677"}

![](img/bifurcation_beta22.png){.absolute .fragment .fade-in top="109" left="163" width="678"}
:::

::: notes
So how did we specify the parameters in our model.
Well, one of the most important parameters is $\beta_i$ as it plays a crucial role in inducing regime changes in dynamics.
And that can be shown with this bifurcation diagram for $\beta$.
Here, the solid lines represent the stable equilibrium, while dashed lines represent unstable equilibrium.
And the red asterisks highlight critical points or also they are called bifurcation points, where the system transitions from one type of behavior to another.

The yellow-shaded area indicates the range of bistability; there are two stable states at 0 and 1 with an unstable state in between.
This area is determined by the relative strength of $\beta$ compared to the other parameters: $\omega_i$, $\delta_i$, and $\alpha_{ii}$.
For simplicity, here I defined the aggregated effects of other symptoms on $S_i$ as $\omega_i$.
So when $\beta$ is smaller than $-\omega_i(\delta_i + 1) - \alpha_{ii}$ (the first critical point), only 0 stands as a stable equilibrium, (CLICK) which can be represented as such energy landscape.
And as $\beta$ surpasses this first critical point, both 0 and 1 become stable states, together with an unstable point in between, (CLICK) which then can be represented by this smooth W shape landscape.
And as $\beta_i$ exceeding $\omega_i$, the second critical point, 0 transitions to an unstable state, leaving 1 as the only stable equilibrium (CLICK).

Presuming inherent bistability in our model as we discussed, we constrain $\beta$ to be within this yellow-shaded bistable region.
Across all symptoms, we set beta to fall within this range, but slightly leaning towards the stable depressed regime like this (CLICK).

Except for the $suicidal$ symptom.
I made one exception for the symptom suicidal, and made the beta to be smaller so it becomes more challenging to become activated. About this, I will show you in more detail in the following slide.
:::


## Simulation setup {.scrollable}

Apply a shock (external trigger) to the system and observe its behavior.

::: panel-tabset
### Shock

![](img/tab1.png){width="80%" fig-align="center"}

<br> <br>

![](img/symptoms_bif.png){width="80%" fig-align="center"}

### Resilience

![](img/tab2.png){width="80%" fig-align="center"}

![](img/anh_resilience.png){width="70%" fig-align="center"}
:::

::: notes
To evaluate if the model can reproduce the fundamental aspects of depression dynamics that I talked about, we simulated the scenarios where a shock was introduced to the system.
This simulated shock is designed to mimic a random sudden stressor such as losing a significant other.

So the way we operationalize the shock was basically adding a stress to each of the symptom which is essentially the same as increasing beta.
So we raised $\beta_i$ proportionally equally across all symptoms, ensuring each symptom experiences a comparable push towards the depressed state.
In this simulation, we increased $\beta_i$ by approximately 33%.

Here the table shows the exact value I used for the simulation.
We simulated over 4000 timepoints, and the shock was given at where t = 1000 and the shock lasted for 500 time points.
And after that, the beta was put back to the original value.

In the plot below, I wanted to show you that how the bistable range differs per symptom given that they have different omega, the aggregated incoming effects from the other symptom.
The plot here shows bifurcation for four different symptoms, along with their energy landscapes before and after the shock, so the orange one is before, and the red one is after.
Symptom anhedonia exhibits the widest bistable range as you can see, because it has the largest aggregated effects from other symptoms.
These wider bistable range implies sort of greater buffer to perturbations, resulting in less transitions between the two stable states.
In contrast, symptom guilty shows the shortest bistable range, as $\omega_{glt}$ is the smallest among the symptoms.
This limited range indicates more frequent transitions between the states upon perturbations, as also shown by the relatively flatter energy landscape.
The orange dotted line in the diagram is the original $\beta_i$ values specified, while the red dotted line is the increased $\beta_i$ value representing the shock.

As I mentioned earlier, an exception was made for the symptom suicidal, where $\beta_i$ is much smaller than the other symptoms; so it positioned farther from the stable depressed regime.
This ensures that even with the increase of stress caused by the shock, the chance that suicidal symptom gets activated is much lower, as can also be seen in its energy landscape.
I made this exception so that it can align with those empirical observations where the suicidal symptom exhibits much lower activation compared to the other symptoms, presumably due to its extreme nature.


(CLICK TAB) And we did this for three different resilience scenarios, each scenario was repeated for 500 times.
Resilience levels are adjusted by modifying the self-reinforcing parameter ($\alpha_{ii}$) and boosting factor ($\delta_i$).
So in the high-resilience scenario, both parameters are reduced to enhance resilience, and in the low-resilience scenario, the parameters are increased to diminish resilience against activation.
Here, you see the example landscape of symptom anhedonia, so you see the valley for depressed state becomes deeper as the resilience level goes down.
:::

## Results {.scrollable}

::: panel-tabset
### Baseline

![](img/eachsym.png) ![](img/eachsym_quant.png) ![](img/totalsym.png)

![](img/triplenetworks.png)

### High resilience

![](img/eachsym_res.png) ![](img/eachsym_quant_res.png) ![](img/totalsym_res.png)

![](img/triplenetworks_res.png)

### Low resilience

![](img/eachsym_low.png) ![](img/eachsym_quant_low.png) ![](img/totalsym_low.png)

![](img/triplenetworks_low.png)
:::

::: notes
So with that set up, we have these results.
This is for the baseline resilience scenario.
So here this plot shows the one example trajectory for each symptom.
The gray shaded area indicates the period when the shock was given to the system.
The first thing you can see is that, upon receiving the shock, all symptoms except for suicidal became activated.
Then, some of the symptoms persist in the activated state even after the shock stops, indicating hysteresis.
Those symptoms with clear hysteresis are turned out to be the ones that are part of the cycles with relatively high in-degree centrality, except for anhedonia.
Also, there is noticeable fluctuation occurring in the guilty symptom, which is due to its narrow bistable range that makes it prone to flipping with small perturbations, as I just showed you in the previous slide.
This fluctuation also affects concentration, because concentration is mainly influenced by guilty.
Lastly, motor does not show much of hysteresis, and the reason is that motor is mainly affected by suicidal, which does barely gets activated in this case.

(SCROLL DOWN) Here you see, this one is the median trajectory over 500 simulations.
And the shaded area represents the interquantile range.
Again, you see some clear fluctuation happening with symptom guilty and its main descendant, the concentration.

(SCROLL DOWN) And if we look at the sum of all symptoms, this is how it looks.
So with the shock the system gets activated and it eventually comes down near the healthy state at the time about 3500.
The horizontal dotted gray lines represents the diagnostic cutoff points according to the PHQ-9 questionnaire, with the lower line indicating mild depression and the higher one is indicating moderate depression.

(SCROLL DOWN) Then, I estimated Gaussian graphical model for each of the phases: before the shock, during, and after the shock.
As you can see, we have some clear differences in terms of network density.
Before the shock when the system was near the healthy state, it shows rather a sparse network, and when the system is approaching the depressed state, the network becomes denser. And even after the shock, the network somewhat maintains a decent level of density.

(TAB) Moving on to the high resilience scenario, now we observe less prolonged activation after the shock, with most symptoms quickly returning to a healthy state ($S = 0$) following its removal.
You still see much more fluctuations with the symptom guilty and concentration, although it is not as obvious as before.

(SCROLL DOWN) And again, this is average trajectories, showing much less hysteresis in general.

(SCROLL DOWN) And the aggregated symptom level also exhibits reduced hysteresis, as the system recovers before where $t = 2000$, shortly after the shock is removed.
Also, we observe a smoother upward curve during the shock, indicating a slower increasing activation compared to the baseline scenario.

(SCROLL DOWN) Accordingly, the network models also reveal much sparser networks throughout the different stages.
Before the shock, the network displays only several very weak connections, looking like almost an empty network.
And during the shock, the network appears relatively dense, although not as dense as in the baseline scenario.

(TAB) Lastly, for the low resilience level.
As expected, all symptoms exhibit more activation compared to the other scenarios.
In this case, even the symptom suicidal is activated upon the introduction of the shock.
Most symptoms remain activated after the shock, with guilty and concentration again showing significant fluctuations.

(SCROLL DOWN) Again, these are average trajectories; most symptoms seem pretty stuck at the activation state.

(SCROLL DOWN) As a result, the average aggregated symptom level remains elevated for a longer time.
It reaches the full activation quickly upon the shock and maintains a moderate depression level thereafter, failing to recover till the end of our simulation.

(SCROLL DOWN) And for the networks, as expected, they are denser than the others.
Especially, the network density before the shock is obviously the highest among all three scenarios.
And of course, during and after the shock, overall connectivity gets strengthened.
:::

## Results (cont.)

*Before the shock* phase comparison

::: {layout="[26,-11, 26, -11, 26]"}
![high resilience](img/blnet_high.png)

![base resilience](img/blnet_base.png)

![low resilience](img/blnet_low.png)
:::

::: notes
Here again, I just put the network estimated before the shock from each of the scenario side-by-side, so that you can easily compare.
So we did find some clear distinctive network structures in different level of resilience. That is one of the points I'd like to highlight.
:::

## Results (cont.)

::: r-stack
![](img/totalnetwork.png){.absolute top="100" left="0" width="500"} ![](img/toymodelnet.png){.fragment .absolute top="100" right="27" width="490"} ![](img/totalnetwork_v2.png){.fragment .absolute top="100" left="0" width="500"}
:::

::: notes
Lastly, to assess how well our model in general can reconstruct the original toy model, I estimated a Gaussian graphical model based on all the simulated data across different resilience levels (1500 iterations over 4000 time points).
This is the resulting estimated network model.

(CLICK) Looking at the network structure, we can see that the overall network resembles the skeleton of the original network.
It retrieves all the edges except for the one between sad and suicidal, which is likely dropped because of our manipulation over the suicidal symptom.

Also, the network shows a clear clustering structure: most nodes on the left side of the simulated network (POINT) are not part of any cycles, while the ones on the right (POINT) are involved in cycles.
(CLICK). If I apply the same coloring scheme, it is easier to see this.
And also, the guilty symptom sort of acts as a bridge between these two clusters, which can be also seen in the original network structure. That I found pretty intriguing.
:::

## Results (cont.) {.scrollable .smaller}

<center>Simulated network vs. Original network</center>

::: {r-stack}
![](img/cent_sim.png){.absolute top="130" left="80" width="390"}

![](img/cent_toy2.png){.absolute top="130" right="70" width="390" height="650"}

![](img/cent_toy_instrength.png){.absolute .fragment top="130" right="70" width="390" height="650"}
:::

::: notes
Then, I looked at the centrality of these networks.
As you know, the simulated one is undirected network, so I computed the strength centrality and for the original model, I computed the in-strength, which is the green line and the out-strength which is the orange line here, as this original network has directions.
So analyzing the strength centrality of the simulated network, I found that they actually quite closely follow the in-strength pattern of the original network.
(CLICK) See, the patterns aligns quite well, with a deviation in motor symptom. 
This deviation is again, because we manipulated the suicidal symptom to rarely get activated. So the motor symptom, which is heavily affected by suicidal now shows a lower strength centrality in our simulated network.

So I found this very interesting... The implication for this is up to discussion, but given this I wanted to emphasize that to some extent we can gather some information about the dynamics based on statistical networks, however, inferring causal relationships, such as talking about intervention targets or key driving nodes, solely based on statistical networks could go very wrong.
:::

## Discussion {background-image="img/bg_sl.png"}

::: {.fragment .semi-fade-out fragment-index="1"}
-   Top-down approach aimed at testing the theorized features of depression dynamics.
:::

::: {.fragment .fade-in-then-semi-out fragment-index="1"}
-   The model stands out from the others:
    -   non-probabilistic nature
    -   continuity
    -   non-linearity
:::

::: {.fragment .fade-in-then-semi-out fragment-index="3"}
-   Future efforts:
    -   specifying the non-linearity
    -   identifying feedback loops
    -   calibrating parameters
:::

::: {.fragment .fade-in fragment-index="4"}
-   Other implications?
:::

::: notes
Alright, so finally discussion.
This study in my opinion was meaningful in a sense it was one of the first attempts to test the theorized features of depression symptom dynamics using a computational model.
So instead of fitting a network from data, here we gave you a more of top-down approach.

And how does our model differs or what does this model adds to the existing ones?
I would say first, this is not a probablistic model, it does not have the component of being active or not active given certain probablity like in an Ising model.
And that also enables us to keep the continuos nature and we can simulate the continuous symptom trajectory instead of being binary.
Also, we've incorporated the non-linarity term that can be controlled by the delta parameter.
This makes our model more flexible by capturing the nonlinear responses in the dynamics.

And of course, this is just very start.
There are much more could be done in the future.
For instance, we would like to investigate further on this non-linearity aspect in the dynamics, as we for now just used a very simple expression, but it probably is not as simple as how we defined in reality.
Also, about the feedback loops and causal directions of the model, I believe we can work on that more in order to find out what is the reasonable directions, ideally substantiated by data; I've been looking into some of the causal algorithms currently.
And with the presence of feedback loops, it is pretty challenging, but I hope in some years there would be some progress on studying the causal structure of symptom network.
Lastly, more of practical aspect; in the follow up of this work, one of the first thing should be to calibrate the parameters and do some sensitivity aaalyses.

And I was hoping that I could hear what you guys think about this.
And if you have any idea on what you can do with this type of model and idea on some interesting extension for this work, I would love to hear it.
:::

## Thank You {background-image="img/bg_sl5.png"}

-   Comments / Questions?
-   Contact: k.park\@uva.nl

::: {#supervisors}
![Vítor Vasconcelos](img/Vitor.png){.absolute top="10" right="300" width="200" height="214"} [Vítor Vasconcelos]{.absolute top="250" right="330"} ![Mike Lees](img/mike.png){.absolute top="10" right="50" width="201"} [Mike Lees]{.absolute top="250" right="110"}
:::

<br> <br> <br> <br> <br> <br>

##### References

::: {#refs}
:::
