---
title: "Modeling Depression Dynamics at the Symptom Level"
subtitle: "Taking a Computational Modeling Approach"
institute: "Apr 19, 2024"  #change date
author: "Kyuri Park"
format: 
  revealjs:
    embed-resources: true
    logo: img/csl_logo.png
    footer: "Computational Science Lab - University of Amsterdam"
    theme: [default, custom.scss]
    slide-number: c/t
    transition: fade
    transition-speed: slow
    background-transition: fade
    preview-links: auto
    html-math-method: mathjax
    auto-stretch: false
    # chalkboard:
    #   boardmarker-width: 5
from: markdown+emoji
title-slide-attributes:
    data-background-image: img/bg_bwcsl.png
    data-background-size: "cover"
    data-background-opacity: "1"
execute:
  echo: false
bibliography: main_ref.bib
csl: "apa.csl"
editor: 
  markdown: 
    wrap: sentence
---

```{r, include=F}
library(knitr)
library(kableExtra)
```


## Network theory of psychopathology
<!-- ::: notes -->
<!-- Hello, I am Kyuri, I am a PhD student working at the Computational Science Lab at the university of amsterdam. -->
<!-- I also used to study here for my undergraduate, majoring in psychological methods.  -->
<!-- Then, I went to Utrecht for my master's, then back to Amsterdam.  -->

<!-- So the main project I am currently working on is about modelling depression dynamics with regard to precariousness factors, which are basically all sorts of risk factors such as low income, bad neighbordhood and so on. -->
<!-- So ultimately we want to understand where to intervene in the system to prevent fully-blown depression and hopefully minimize the mental health problems. -->
<!-- That's the grand scheme, but as a first baby step, I've started working on modeling depression symptoms, which is the work that I am planning to present today. -->
<!-- But this is still an on-going work and the goal for me today to share this with you guys is to  pick some of your brains to get some interesting implications and of course improvements for future. But i am already aware of a lot of limitations so I encourage you to approach this with an open mind and full of positivity. And just a heads up, i am not a good public speaker, so if you are confused, you are probably rightfully being so. Feel free to ask for clarification; I will give it another go, as long as the time allows. -->
<!-- ::: -->
Mental disorder is produced by direct causal interactions between symptoms that reinforce each other via feedback loops.
[@BorsboomCramer2013].

::: r-stack
![](img/cycle1.png){.fragment fig-align="center" width="450"}

![](img/cycle2.png){.fragment fig-align="center" width="450"}

![](img/cycle3.png){.fragment fig-align="center" width="450"}

![](img/cycle4.png){.fragment fig-align="center" width="450"}

![](img/cycle5.png){.fragment fig-align="center" width="450"}

![](img/cycle2.png){.fragment fig-align="center" width="450"}

![](img/cycle3.png){.fragment fig-align="center" width="450"}

![](img/cycle4.png){.fragment fig-align="center" width="450"}

![](img/cycle5.png){.fragment fig-align="center" width="450"}
:::

::: notes
The main foundation for me when I start looking into modelling depression symptom dynamics is the network theory of psychopathology of Denny, which says mental disorder is produced by direct causal interactions between the symptoms.
And the crucial point here is that, these causal interactions often form feedback loops and they reinforce each other.
As you can see here, feeling down makes you sleep poorly and lack of sleep makes you feel tired and it sort of forms this vicious cycle.
Like that symptom activation spreads throughout the network, and when those cyclic relationships become strong enough and symptom activation sustains itself, that manifests as a depression.
So that's the gist of the theory.
:::

## Fundamental features of depression dynamics

::: {#citeborsboom}
[@borsboom2017network; @cramer_major_2016]
:::

1.  [Bistability]{.fragment .highlight-current-red fragment-index="1"}

2.  [Network connectivity]{.fragment .highlight-current-red fragment-index="2"}

3.  Hysteresis

4.  Resilience

::: r-stack
![](img/landscape.png){.absolute .fragment .fade-in-then-out top="90" left="545" width="403.5" height="317" fragment-index="1"}

![](img/landscape_networks.png){.absolute .fragment .fade-in top="90" left="500" width="540" height="600" fragment-index="2"}
:::

::: notes
Given the network theory, here I picked four fundamental features of depression dynamics to focus on in this study and test with my model.
The first one is bistability, which suggests that depression, as a dynamic system, exhibits two stable states: one represents healthy state and the other represents depressed state.
This notion is often illustrated using an energy landscape analogy with hills and valleys like this.

And second one is network connectivity.
With the introduction of the network theory, there has been increasing evidence that clinically depressed groups have stronger network connections compared to healthy controls.
Accordingly, the two stable states are presumed to be distinguishable by a weakly connected network in the healthy population and a strongly connected network in the depressed population.
:::

## Fundamental features of depression dynamics {.scrollable}

::: {#citeborsboom}
[@borsboom2017network; @cramer_major_2016]
:::


1.  Bistability

2.  Network connectivity

3.  [Hysteresis]{style="color:#FF0000"}

4.  Resilience


::: r-stack
![](img/hysteresis0.png){.absolute top="380" left="20"} ![](img/hysteresis1.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="1" width="2600"} ![](img/hysteresis2.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="2" width="2600"} ![](img/hysteresis3.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="3" width="2600"} ![](img/hysteresis4.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="4" width="2600"} ![](img/hysteresis5.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="5" width="2600"} ![](img/hysteresis6.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="6" width="2600"} ![](img/hysteresis7.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="7" width="2600"} ![](img/hysteresis8.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="8" width="2600"} ![](img/resilience1.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="9" width="2600"}

:::
<br>
<br>

::: notes
Third one is hysteresis.
In psychopathology, hysteresis refers to, quoting Denny, the phenomenon that symptoms continue to activate each other, even after the triggering factor has disappeared.

In this figure, the shaded area represents the period when the system experiences stress or shock.
And here you see, after this trigger is removed, the system does not return to a healthy state immediately but remains lingering near the depressed state.

As you see here with the symptom network representation, the symptom gets activated with the external trigger, the "e" node, but even when the trigger is gone, the symptoms remain activated.
So this property right here is called hysteresis, that we are going to focus on.
(CLICK)

And this network that has relatively strong connection with feedback loops, which enables hysteresis to show, we call it a vulnerable network or low resilient network.
Although here I did not indicate the causal directions but I assume these three nodes form a cycle.
:::

## Fundamental features of depression dynamics {.scrollable}

::: {#citeborsboom}
[@borsboom2017network; @cramer_major_2016]
:::


1.  Bistability

2.  Network connectivity

3.  Hysteresis

4.  [Resilience]{style="color:#FF0000"}


::: r-stack
![](img/resilience1.png){.absolute .fragment .fade-out top="380" left="20" width="2600" fragment-index="1"} <!-- ![](img/resilience2.png){.absolute .fragment .fade-up top="380" left="20" fragment-index="1" width="2600"} --> 
![](img/resilience3.png){.absolute .fragment .fade-up top="380" left="20" width="920" fragment-index="1"}
![](img/resilience4.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="2" width="1500"}
![](img/resilience5.png){.absolute .fragment .fade-in top="380" left="20" fragment-index="3" width="1500"}
:::

::: notes
This resilience concept is the last point that I want to talk about.
Opposite to this low resilient network, when the network has relatively weak connections, we call it a highly resilient network.
Because in this case, the symptom activation does not easily propagate through the network.

So in this study, what we are gonna do with our model is that we are going to assess whether we can replicate these features of depression dynamics.
For example, for resilience, we will specify different levels of resilience within our model and see whether the resulting network models exhibit different structures.
So this is sort of top-down approach, evaluating whether the proposed features of depression dynamics are supported within our modeling framework.
<!-- So in this study, with our model that I am going to show, we are going to assess whether we can replicate these features of depression dynamics, except for bistability. -->
<!-- For bistability, we would more or less presume that our system has bistability and we formalize our model such that it satisfies this condition. -->
<!-- For the rest, we will see if our model can retrieve such features through our simulation. -->
<!-- For example, for resilience, we will specify different levels of resilience within our model and examine whether the resulting statistical network models exhibit different structures. -->
<!-- So this is sort of top-down approach, evaluating whether the proposed features of depression dynamics are supported within our modeling framework. -->
:::

## Toy model {.smaller}

Adjacency matrix (for the weighted directed graph) determined based on insights from some empirical studies [@ramos-vera_network_2021; @lee_measurement_2023; @jing_comparing_2023] and practical judgment.

::: r-stack
![](img/netA.png){.absolute .fragment .semi-fade-out left="0" top="200" width="450" fragment-index="1"} ![](img/toymodel.png){.absolute .fragment .fade-in right="0" top="200" width="600" fragment-index="1"}
:::

::: notes
So this is the toy model we used.
I didn't really have any data back then, so I relied on insights from some empirical studies and mainly common sense to determine the weights and causal directions, which results in this adjacency matrix, A. So it is literally a toy model.

When visualized in a network, we get this.
Note that the self-loops are included in our model even though empirical networks did not have those.
And also all these causal links are positive, meaning that every feedback loops are reinforcing.
Lastly, here, I colored the nodes that are part of cycles in orange, and the ones that are not part of any cycles in blue.
:::

## Formalizing dynamics {.smaller .scrollable}

-   Deterministic differential equation (`ODE`^1^):

<br> <br>

```{=tex}
\begin{equation} \label{eq:2}
\frac{dS_i}{dt} = S_i(1-S_i)(\beta_i + \alpha_{ii}S_i + \sum_{i \neq j}\alpha_{ji}S_j(1 + \delta_i f(S_i)))
\end{equation}
```
<br> <br>

-   Add (white) noise (`SDE`^2^):

```{=tex}
\begin{equation} \label{eq:3}
dS_{i} = S_{i}(1-S_{i})(\beta_i + \alpha_{ii} S_{i} + \sum_{i \neq j}\alpha_{ji}S_{j}(1+\delta_i f(S_{i}))) dt + \sigma_i dW_i
\end{equation}
```
<br>

::: {#footnotes_eq}
^1^: Ordinary Differential Equation.\
^2^: Stochastic Differential Equation.\
$f(x) = x^2$.
:::

<br> <br> <br> <br> <br> <br> <br>

#### Description of parameters

| Parameter  | Description                                                                                                                                                                                             |
|--------------------------|:---------------------------------------------|
| $\beta_i$  | The sensitivity level of $S_i$ to external triggering factors.                                                                                                                                          |
| $\alpha$   | The elements of the weight matrix $\mathbf{A}$. <BR> $\alpha_{ij}$ refers to the weight of the edge $S_i \rightarrow S_j$ and $\alpha_{ii}$ refers to the weight of the self-reinforcing loop of $S_i$. |
| $\delta_i$ | The boosting factor that amplifies the effect of other $S_j$'s on $S_i$.                                                                                                                                |
| $\sigma_i$ | The scaling factor that controls the strength of the stochastic term.                                                                                                                                   |

![](img/bifurcation_W.png){fig-align="center"}

::: notes
So this is the model we used for symptom dynamics.
The first top expression shows the ODE, the ordinary differential equation, defining the interaction between the symptoms.
So the $S_i$ here corresponds to a symptom i.
Let me go through this equation term by term with you, so you know how we came up with this.
The first two terms $S_i(1-S_i)$ are typical logistic differential equation, which we put to constrain the symptom level between 0 and 1.
We imposed this constraint to align with the common practice of measuring symptoms on bounded scales in questionnaires.
In this context, approaching 0 means a low symptom level, indicating symptom deactivation, and approaching 1 indicates symptom activation.

The third term is a sum of three different elements that collectively determine the symptom level.
Here, $\beta_i$ represents the sensitivity level of $S_i$.
A lower $\beta_i$ indicates reduced sensitivity to external triggering factors, making the symptom less prone to activation.
It is an important parameter, which heavily influences the system's tipping point, so I will talk about this in more detail in the following slide.

$\alpha$ denotes the weight of edges in the network, basically the elements of matrix $\mathbf{A}$. $\alpha_{ii}$ is the diagonal of the matrix A, the self-reinforcing loop.
And $\alpha_{ji}$ represents the impact of $S_j$ on $S_i$, and $\delta_i$ acts as a booster, making the influence of other symptoms on $S_i$ stronger, depending on the current level of $S_i$.
And here we define $f$ to be a quadratic function, because it seems to be one of the simplest functions I could think of for a monotonic non-linear increasing function, but it was my arbitrary choice. So in the end what it says is that, as the $S_i$ level increases, the effects of other symptoms are amplified by $\delta_i \cdot S_i^2$.

And this term is important because this actually adds the nonlinearity into our model because this is the interaction term between $S_i$ and $S_j$, which can be turned on and off by this delta.

Any questions?...
It would be insane if everything clicks straight away, just let it sink for now, and hopefully it becomes clearer when I show you the plots on how the model behaves.

And this second equation, is just to show that we introduced the noise to our model to capture the inherent randomness observed in symptom dynamics.
The noise is usually seen as blurring trajectories in deterministic systems, but the noise can actually facilitate transitions between different states, so the strength of this noise is therefore very important.
Here we control the noise strength with $\sigma_i$.
And the underlying nature of the noise in our model is Gaussian white noise, which is a common choice for capturing random fluctuations.
Adding this noise term, we can describe the dynamics of symptoms with this SDE, the stochastic differential equation.
So that is all the equations I have.

So, this is a quick summary of what are the different parameters doing in our model.
Are these okay-ish clear?
Then I will show you a bit more in detail how does the dynamics look given this model.
:::

## Simulation setup

Apply a shock (external trigger) to the system and observe its behavior.

::: r-stack
![](img/bifurcation_beta1.png){.absolute top="240" left="180.1" width="661"} ![](img/bifurcation_beta2.png){.absolute .fragment .fade-in top="210" left="163" width="678"} ![](img/bifurcation_beta3.png){.absolute .fragment .fade-in top="159" left="162" width="677"} ![](img/bifurcation_beta4.png){.absolute .fragment .fade-in top="149" left="162" width="678"} ![](img/bifurcation_beta5.png){.absolute .fragment .fade-in top="150" left="163" width="677"} ![](img/bifurcation_beta6.png){.absolute .fragment .fade-in top="149" left="163" width="676"}
:::

::: notes
So to observe how this model behaves, we design a simulation where we apply a shock to the system, which can be seen as an external trigger. 

So the way we operationalize the shock was basically adding a stress to each of the symptom which is essentially the same as increasing beta.

But the question is then, how we defined the beta. And that can be shown with this bifurcation diagram for $\beta$. Let's look at this together.
So here, the solid lines represent the stable equilibrium, while dashed lines represent unstable equilibrium.
And the red asterisks highlight critical points or they are also called bifurcation points, where the system transitions from one type of behavior to another.

The yellow-shaded area indicates the range of bistability; there are two stable states at 0 and 1 with an unstable state in between.
This area is determined by the relative strength of $\beta$ compared to the other parameters here, which are $\omega_i$, $\delta_i$, and $\alpha_{ii}$.
For simplicity, here I defined the aggregated effects of other symptoms on $S_i$ as $\omega_i$.
So when $\beta$ is smaller than the first critical point, only 0 stands as a stable equilibrium, (CLICK) which can be represented as such energy landscape like this.
And as $\beta$ surpasses this first critical point, both 0 and 1 become stable states (CLICK) which then can be represented by this smooth W shape bi-stable landscape.
And as $\beta_i$ exceeding $\omega_i$, the second critical point, 0 transitions to an unstable state, leaving 1 as the only stable equilibrium (CLICK), as you can see in this landscape.


Presuming inherent bistability in our model as we discussed, we constrain $\beta$ to be within this bistable region.
So across all symptoms, we set the beta to fall within this range, but slightly leaning towards the stable depressed regime like this (CLICK).

Then, when we give the shock to system, we raise $\beta_i$ like this, closer to the second critical point, where depressed state is the only stable equilibrium. So the symptoms will likely go towards the depressed regime. 
<!-- So across all the symptoms, we increase beta proportionally equal amount, making sure that each symptom experiences a comparable push towards the depressed state.  -->

But there is one exception made, for the $suicidal$ symptom.
For the suicidal symptom, we set the beta to be smaller to begin with, so it is more challenging to get activated.
And the reason why we did this is, to make it align with those empirical observations where the suicidal symptom exhibits much lower activation compared to the other symptoms, probably because of its extreme nature. okay?



:::

## Simulation setup (cont.) {.scrollable}

Simulate across three different resilience level scenarios.

::: panel-tabset
### Resilience

![](img/tab2.png){width="80%" fig-align="center"}

![](img/anh_resilience.png){width="70%" fig-align="center"}

### Shock

![](img/tab1.png){width="80%" fig-align="center"}

![](img/symptoms_bif.png){width="80%" fig-align="center"}
:::

::: notes
Then, we did this for three different resilience scenarios.
Resilience levels are adjusted by modifying the self-reinforcing factor ($\alpha_{ii}$) and boosting factor ($\delta_i$).
So in the high-resilience scenario, both parameters are reduced to enhance resilience, and in the low-resilience scenario, they are increased to lower resilience against activation.
Here, you see the example landscape of symptom anhedonia, so you see that the valley for depressed state becomes deeper and deeper as the resilience level goes down.


Here the table shows the exact value I used for the simulation.
We simulated over 4000 timepoints, and the shock was given at where t = 1000 and the shock lasted for 500 time points.
And after that, the beta was put back to the original value.

In the plot below, I wanted to show you that how the bistable range differs per symptom given that they have different omega, the aggregated incoming effects from the other symptom.
The plot here shows bifurcation for four different symptoms, along with their energy landscapes before and after the shock, so the orange one is before, and the red one is after.
Symptom anhedonia exhibits the widest bistable range as you can see, because it has the largest aggregated effects from other symptoms. 
These wider bistable range implies sort of greater buffer to perturbations, resulting in less transitions between the states by random perturbations.
In contrast, symptom guilty shows the shortest bistable range, as $\omega_{glt}$ is the smallest among the symptoms.
This limited range indicates more frequent transitions between the states upon perturbations, as also shown by the relatively flatter energy landscape.
The orange dotted line in the diagram is the original $\beta_i$ values specified, and the red dotted line is the increased $\beta_i$ value used as a shock.

As I mentioned earlier, an exception was made for the symptom suicidal, where $\beta_i$ is much smaller than the other symptoms; so it positioned farther from the stable depressed regime.
This ensures that even with the increase of stress caused by the shock, the chance that suicidal symptom gets activated is much lower, as can also be seen in its energy landscape.
I made this exception so that it can align with those empirical observations where the suicidal symptom exhibits much lower activation compared to the other symptoms, presumably due to its extreme nature.
:::

## Results {.scrollable}

::: panel-tabset
### Baseline

![](img/eachsym.png) ![](img/eachsym_quant.png) ![](img/totalsym.png)

![](img/triplenetworks.png)

### High resilience

![](img/eachsym_res.png) ![](img/eachsym_quant_res.png) ![](img/totalsym_res.png)

![](img/triplenetworks_res.png)

### Low resilience

![](img/eachsym_low.png) ![](img/eachsym_quant_low.png) ![](img/totalsym_low.png)

![](img/triplenetworks_low.png)
:::

::: notes
So the results. Quickly about the set up, so for each iteration, we simulated over 4000 timepoints, and the shock was given at where t = 1000 and the shock lasted for 500 time points.
And for each scenario, we repeated the simulation for 500 times. Alright?

So this is for the baseline resilience scenario.
So here this plot shows the one example trajectory for each symptom.
The gray shaded area indicates the period when the shock was given to the system.
The first thing you can see is that, upon receiving the shock, all symptoms except for suicidal became activated.
Then, some of the symptoms persist in the activated state even after the shock stops, indicating hysteresis.
Those symptoms with clear hysteresis are turned out to be mostly the nodes that are part of the cycles with relatively high in-degree centrality.
<!-- Also, there is noticeable fluctuation occurring in the guilty symptom, which is due to its narrow bistable range that makes it prone to flipping with small perturbations. -->
<!-- This fluctuation also affects concentration, because concentration is mainly influenced by guilty. -->
<!-- Lastly, motor does not show much of hysteresis, and the reason is that motor is mainly affected by suicidal, which does barely gets activated in this case. -->

(SCROLL DOWN) Here you see, this one is the median trajectory over 500 simulations.
And the shaded area represents the interquantile range.
Again, you see some clear hysteresis effect for some of the symptoms.

(SCROLL DOWN) And if we look at the sum of all symptoms, this is how it looks. 
Again, the red line is median, and shaded area is interquantile range.
So with the shock the system gets activated and it eventually comes down near the healthy state at the time about 3500.
The horizontal dotted gray lines represents the diagnostic cutoff points according to the PHQ-9 questionnaire, with the lower line indicating mild depression and the higher one is indicating moderate depression.

(SCROLL DOWN) Then, I estimated Gaussian graphical model for each of the phases: before the shock, during, and after the shock.
As you can see, we have some clear differences in terms of network density.
Before the shock when the system was near the healthy state, it shows rather a sparse network, and when the system is approaching the depressed state, the network becomes denser.
And even after the shock, the network somewhat maintains a decent level of density.

(TAB) Moving on to the high resilience scenario, now we observe less prolonged activation after the shock, with most symptoms quickly returning to a healthy state, as the shock is removed.
<!-- You still see much more fluctuations with the symptom guilty and concentration, although it is not as obvious as before. -->

(SCROLL DOWN) And again, this is median trajectories, showing much less hysteresis in general.

(SCROLL DOWN) And the aggregated symptom level also exhibits reduced hysteresis, as the system recovers before where $t = 2000$, shortly after the shock is removed.
Also, we observe a smoother upward curve during the shock, indicating a slower increasing activation compared to the baseline scenario.

(SCROLL DOWN) Accordingly, the network models also reveal much sparser networks throughout the different stages.
Before the shock, the network displays only several very weak connections, looking like almost an empty network.
And during the shock, the network appears relatively dense, although not as dense as in the baseline scenario.

(TAB) Lastly, for the low resilience level.
As expected, all symptoms exhibit more activation compared to the other scenarios.
You see in this case, even the symptom suicidal is activated upon the introduction of the shock.

(SCROLL DOWN) Again, these are median trajectories; most symptoms seem pretty stuck at the activation state.

(SCROLL DOWN) As a result, the aggregated symptom level remains elevated for a longer time.
It reaches the full activation quickly upon the shock and maintains a moderate depression level thereafter, failing to recover till the end of our simulation.

(SCROLL DOWN) And for the networks, as expected, they are denser than the others.
Especially, the network density before the shock is obviously the highest among all three scenarios.

So in summary, we did find some clear hysteresis effects in our model, and also variations in network connectivity across different time phases as well as different resilience level. And just to point out, these various networks are generated based on the same mechanistic model.
:::

## Results (cont.)

*Before the shock* phase comparison

::: {layout="[26,-11, 26, -11, 26]"}
![high resilience](img/blnet_high.png)

![base resilience](img/blnet_base.png)

![low resilience](img/blnet_low.png)
:::

::: notes
Here again, I just put the network estimated before the shock from each of the scenario side-by-side, so that you can easily compare.
So this shows distinctive network structures in different level of resilience and just want to emphasize once again that they are based on the same underlying model, and in this case they only slightly differ with a couple of parameter values.
:::

## Results (cont.)

Network estimated from aggregated simulated data across time and resilience levels.

::: r-stack
![](img/totalnetwork.png){.absolute top="120" left="0" width="500"} [simulated network]{.absolute bottom="40" left="150" style="font-size: 0.7em;"}

![](img/toymodelnet.png){.fragment .absolute top="120" right="27" width="490" fragment-index="1"} [original network]{.absolute .fragment bottom="40" right="150" fragment-index="1" style="font-size: 0.7em;"}

![](img/totalnetwork_v2.png){.fragment .absolute top="120" left="0" width="500" fragment-index="2"}
:::

::: notes
Finally, to assess how well our model in general can reconstruct the original toy model, I estimated a Gaussian graphical model based on all the simulated data aggregated across time and resilience levels.
This is the resulting estimated network model.

(CLICK) Looking at the network structure, we can see that the overall network resembles the skeleton of the original network. Let me remind you the toy model again.
It retrieves all the edges except for the one between sad and suicidal, which is likely dropped because of our manipulation over the suicidal symptom.

Also, the network shows a clear clustering structure: most nodes on the left side of the simulated network are not part of any cycles, while the ones on the right side are part of cycles.
(CLICK).
If I apply the same coloring scheme, it is easier to see this.
And also, the guilty symptom sort of acts like a bridge between these two clusters, which can be also seen in the original network structure.
That I found pretty intriguing.
:::

## Results (cont.) {.scrollable .smaller}

<center>Simulated network   vs.   Original network</center>

::: {r-stack}
![](img/cent_sim.png){.absolute top="130" left="180" width="300"}

![](img/cent_toy2.png){.absolute top="132" right="160" width="300" height="503"}

![](img/cent_toy_instrength.png){.absolute .fragment top="132" right="160" width="300" height="503"}
:::

::: notes
Then, I looked at the centrality of these networks.
As you know, the simulated one is undirected network, so I computed the strength centrality and for the original model, I computed the in-strength, which is the green line and the out-strength which is the orange line here.
So analyzing the strength centrality of the simulated network, I found that they actually quite closely follow the in-strength pattern of the original network.
(CLICK) See, the patterns aligns quite well, with a deviation in the motor and suicidal symptom.
This deviation is again, because we manipulated the suicidal symptom to rarely get activated.
So the motor symptom, which is heavily affected by suicidal now shows a lower strength centrality in our simulated network.

So I found this very interesting... The implication for this is up to discussion, but given this I wanted to emphasize that to some extent we can gather some information about the dynamics based on statistical networks, however, inferring causal relationships, such as talking about intervention targets or key driving nodes, solely based on statistical networks could go very wrong.
:::

## Discussion {background-image="img/bg_sl.png"}

::: {.fragment .semi-fade-out fragment-index="1"}
-   Top-down approach to test the theorized features of depression dynamics.
:::

::: {.fragment .fade-in-then-semi-out fragment-index="1"}
-   The model stands out from the others:
    -   non-linearity
    -   continuity 

:::

![](img/palmer_prediction.png){.absolute top="150" right="50" width="400" .fragment  .fade-in-then-semi-out fragment-index="2"}
[@palmer2000predicting]{style="font-size:0.7em;" .absolute top="450" right="70" .fragment .fade-in-then-semi-out fragment-index="2"}

::: {.fragment .fade-in-then-semi-out fragment-index="3"}
-   Future efforts:
    -   specifying the non-linearity
    -   identifying feedback loops / casual directions
    -   calibrating parameters
:::

::: {.fragment .fade-in fragment-index="4"}
-   Other implications?
:::



::: notes
Alright, so finally discussion.
This study in my opinion was meaningful in a sense it was one of the first attempts to test the theorized features of depression symptom dynamics using a computational model.
So instead of fitting a network from data, here we gave you a more of top-down approach.

And how does our model differs or what does this model actually adds to the existing ones? (Han actually asked me this before).

I would say first, we've incorporated the non-linearity term that can be controlled by the delta parameter, which makes our model more flexible by being able to capture the nonlinear responses in the dynamics.

And secondly, our model differs in its continuous nature, which allows us to simulate symptom trajectories continuously rather than getting binary responses, such as in the Ising model. 

And this continuity can actually provide a significant advantage. Lourens, who unfortunately couldn't join us today, introduced me to this work from Palmer, who mainly works in climate and weather prediction. The core concept of Palmer's work revolves around the idea that with sufficient information about the initial state, we can potentially predict the continuous trajectory of a dynamical system.

In this case, they were predicting temperature using what they call an ensemble prediction model. This model essentially adds perturbations to the initial conditions and generate trajectories based on stochastic differential equations. In the graph, you see the dashed line, that is the actual temperature, and the gray lines represent trajectories from the model. And here, their predictions were quite okay, as the real temperature fell within the predicted bounds.

So this shows one of the possibilities that such continuous model could also be utilized in psychological research, to make a short-term prediction like this, so for example it could be used to make a short-term prognosis or so. 




But of course, this is just a very start.
There are much more could be done in the future.
For example, we would actually like to investigate further on this non-linearity aspect in the dynamics, as we for now just used a very simple expression, but it probably is not as simple as how we defined in reality.
Also, about the feedback loops and causal directions of the model. It is one of the hot topics, causality and causal discovery. I am also very much interested in this and I've bothered Lourens a lot in the past, trying to understand this more.
The thing is there are some promising causal algorithms that could learn the causal structure even with the feedback loops present in the model. So hopefully with the data I have now, I would like to delve deeper into this. If anyone working on causal discovery / causal inference, I would like to hear about what you think about this as well.
Lastly, more of practical aspect; for the follow up of this work, one of the first thing should be done is to calibrate the parameters and do some sensitivity analyses.

And I was really hoping that I could hear what you guys think about this model.
And if you have any idea on what you can do with this type of models or any interesting extensions for this work, I would love to hear it.
:::

## Thank You {background-image="img/bg_sl5.png"}

-   Comments / Questions?
-   Contact: k.park\@uva.nl

::: {#supervisors}
![Vítor Vasconcelos](img/Vitor.png){.absolute top="10" right="300" width="200" height="214"} [Vítor V. Vasconcelos]{.absolute top="250" right="330"} ![Mike Lees](img/mike.png){.absolute top="10" right="50" width="201"} [Mike Lees]{.absolute top="250" right="110"}
:::

<br> <br> <br> <br> <br> 

##### References

::: {#refs}
:::

::: notes
Thank you very much. I'd like to thank to my supervisors, Vitor Vasconcelos and Mike Lees, who have been guiding me through this work. Also if you have any comments or questions, please feel free to reach out to me via email. I'm always open to discussion and feedback. Alright, thanks a lot again for your attention.
:::